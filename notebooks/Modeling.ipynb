{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sqlalchemy\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "import src.transform as t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pass\n",
    "\n",
    "trips_long = gpd.read_postgis('trips_long', engine, geom_col='geom_coord')\n",
    "trips_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_raw = clean.plus_minus_locations(rides_long, 'ANC')\n",
    "locations_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "three_hour_rolling = clean.cumulative_change(locations_raw, window_size='3H')\n",
    "three_hour_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which series have the largest ranges? About half of these perform much differently than the others\n",
    "# Worth noting that ANC's in seven and eight have very light differencing\n",
    "min_max_diff = three_hour_rolling.aggregate(['min','max']).transpose()\n",
    "min_max_diff.columns = ['minimum', 'maximum']\n",
    "min_max_diff['range'] = min_max_diff.maximum - min_max_diff.minimum\n",
    "min_max_diff.sort_values('range', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are large spikes here around for example early June, but let's see how SARIMA does, with a daily seasonal component (24 hours per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_series(three_hour_rolling['5D'],train_end='2020-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = three_hour_rolling['5D'].resample('1H').mean()\n",
    "viz.plot_series(series,train_end='2020-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = three_hour_rolling['1A'].resample('1H').mean()\n",
    "\n",
    "# Leaving aside month of July as a Test Set, this is about 25% of the data\n",
    "test_start = '2020-07-01 00:00:00'\n",
    "\n",
    "# Make the train/test splits\n",
    "train = series[series.index < test_start]\n",
    "test = series[test_start:]\n",
    "\n",
    "# Checking output lens add up to len of series (they do)\n",
    "print(len(series), len(test), len(train))\n",
    "\n",
    "# model\n",
    "model = SARIMAX(train, order=(0,1,1), seasonal_order=(0,1,1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = result.predict(start=train.index[0], end=test.index[-1], dynamic=test_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX crushes it in-sample, even catching huge spikes, it does much less well as distance out of sample decreases\n",
    "\n",
    "- Since our business use case is for fleet rebalancing on an intraday basis rather than predicting out of sample forecast one month out, it seems quite fair to use walk-forward modeling here\n",
    "- Future improvement: would reaaaaallly like to add a seasonal weekly component with s=168 (i.e. both daily s=24, and weekly s=168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = viz.plot_series(series, train_end=test_start, preds=preds, fig_size=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_title('Naive SARIMA model Prediction 1 Month out of Sample for ANC 1A \\n config=(0,1,1)(0,1,1,24)')\n",
    "fig.savefig('../figures/declining_out_of_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xlim(ax.set_xlim([dt.date(2020, 6, 30), dt.date(2020, 7, 2)]))\n",
    "ax.set_title('Naive SARIMA model Prediction 1 Day out of Sample for ANC 1A \\n config=(0,1,1)(0,1,1,24) -- Full Train Set Starts 2020-04-01')\n",
    "fig.savefig('../figures/one_day_pred_no_walk_forward.png')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_daily1A = result.summary()\n",
    "summary_daily1A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempting a Weekly Seasonal with s=168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = three_hour_rolling['1A'].resample('1H').mean()\n",
    "\n",
    "# Leaving aside month of July as a Test Set, this is about 25% of the data\n",
    "test_start = '2020-07-01 00:00:00'\n",
    "\n",
    "# Make the train/test splits\n",
    "train = series[series.index < test_start]\n",
    "test = series[test_start:]\n",
    "\n",
    "# Checking output lens add up to len of series (they do)\n",
    "print(len(series), len(test), len(train))\n",
    "\n",
    "# model\n",
    "model = SARIMAX(train, order=(0,1,1), seasonal_order=(0,1,1,168))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = result.predict(start=train.index[0], end=test.index[-1], dynamic=test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_geo.started_at.value_counts().head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_recent[cleaned_recent.started_at > cleaned_recent.ended_at]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_geo[recent_geo.started_at.isin(recent_geo.started_at.value_counts().head(60).index) & (recent_geo.duration_seconds == 1118.0)].start_station_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_geo[recent_geo.started_at == '2020-07-23 11:24:54']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = pd.concat(raw_dfs[:-4])\n",
    "historical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
